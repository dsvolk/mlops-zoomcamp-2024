{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fda34",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2a6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\")\n",
    "df_feb = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d486a589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ab5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_jan.columns) == len(df_feb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2bb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d138c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1047507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PULocationID\"].nunique() + df[\"DOLocationID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39dc4d",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 32.59\n",
    "* 42.59\n",
    "* 52.59\n",
    "* 62.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f76dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbf0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]) / pd.Timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466be11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3066766.00\n",
       "mean          15.67\n",
       "std           42.59\n",
       "min          -29.20\n",
       "25%            7.12\n",
       "50%           11.52\n",
       "75%           18.30\n",
       "max        10029.18\n",
       "Name: duration, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"duration\"].describe().apply(lambda x: format(x, \".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9c968",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "931604a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_raw_records = len(df)\n",
    "df = df[(1 <= df[\"duration\"]) & (df[\"duration\"] <= 60)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d48d96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812202822125979"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) / n_raw_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe26e5",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420fac0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dicts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPULocationID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDOLocationID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train_dicts = (df[\"PULocationID\"].astype(str) + \"_\" + df[\"DOLocationID\"].astype(str)).to_dict()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dv \u001b[38;5;241m=\u001b[39m DictVectorizer()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/core/frame.py:2178\u001b[0m, in \u001b[0;36mDataFrame.to_dict\u001b[0;34m(self, orient, into, index)\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;124;03mConvert the DataFrame to a dictionary.\u001b[39;00m\n\u001b[1;32m   2077\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;124;03m defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_dict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_dict\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/core/methods/to_dict.py:221\u001b[0m, in \u001b[0;36mto_dict\u001b[0;34m(df, orient, into, index)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m are_all_object_dtype_cols:\n\u001b[1;32m    218\u001b[0m     rows \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(columns, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    222\u001b[0m         into_c((k, maybe_box_native(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows\n\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    226\u001b[0m         into_c(\u001b[38;5;28mzip\u001b[39m(columns, t)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    227\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/core/methods/to_dict.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m are_all_object_dtype_cols:\n\u001b[1;32m    218\u001b[0m     rows \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(columns, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 222\u001b[0m         \u001b[43minto_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaybe_box_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows\n\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    226\u001b[0m         into_c(\u001b[38;5;28mzip\u001b[39m(columns, t)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    227\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/core/methods/to_dict.py:222\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m are_all_object_dtype_cols:\n\u001b[1;32m    218\u001b[0m     rows \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(columns, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 222\u001b[0m         into_c((k, \u001b[43mmaybe_box_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows\n\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    226\u001b[0m         into_c(\u001b[38;5;28mzip\u001b[39m(columns, t)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    227\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/mlz/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:201\u001b[0m, in \u001b[0;36mmaybe_box_native\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_bool(value):\n\u001b[1;32m    200\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(value)\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimedelta64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    202\u001b[0m     value \u001b[38;5;241m=\u001b[39m maybe_box_datetimelike(value)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m NA:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dicts = df[[\"PULocationID\", \"DOLocationID\"]].astype(str).to_dict(orient=\"records\")\n",
    "# train_dicts = (df[\"PULocationID\"].astype(str) + \"_\" + df[\"DOLocationID\"].astype(str)).to_dict()\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae73a56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3009173x515 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6018346 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9aca7d",
   "metadata": {},
   "source": [
    "\n",
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64\n",
    "* 11.64\n",
    "* 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbe71c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.649261929201487"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"duration\"\n",
    "y_train = df[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "root_mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566c848",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a087627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb[\"duration\"] = (df_feb[\"tpep_dropoff_datetime\"] - df_feb[\"tpep_pickup_datetime\"]) / pd.Timedelta(minutes=1)\n",
    "df_feb = df_feb[(1 <= df_feb[\"duration\"]) & (df_feb[\"duration\"] <= 60)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970dd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_feb[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dcef4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dicts = df_feb[[\"PULocationID\", \"DOLocationID\"]].astype(str).to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19a117ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.811819793542861"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(y_val, lr.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3106b7",
   "metadata": {},
   "source": [
    "## Memorization experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405489d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature which is a combination of PULocationID and DOLocationID\n",
    "df[\"PULocationID\"] = df[\"PULocationID\"].astype(str)\n",
    "df[\"DOLocationID\"] = df[\"DOLocationID\"].astype(str)\n",
    "df[\"PU_DO\"] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]\n",
    "\n",
    "# Compute the average duration and count for each PU_DO combination\n",
    "df_lookup = (\n",
    "    df.groupby(\"PU_DO\")\n",
    "    .agg(duration=(\"duration\", \"mean\"), count=(\"duration\", \"count\"))\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Create a dictionary to map N most frequent PU_DO combinations to average duration\n",
    "N = 100 # Number of most frequent PU_DO combinations to consider\n",
    "lookup_dict = {k: v[\"duration\"] for k, v in df_lookup.iloc[:N].to_dict(orient=\"index\").items()}\n",
    "\n",
    "global_mean = df[\"duration\"].mean() # Global average duration, to be used as fallback\n",
    "\n",
    "# Define a function to predict the duration based on PU_DO combination\n",
    "def predict(pu_do: str) -> float:\n",
    "    return lookup_dict.get(pu_do, global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f965d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PU_DO\"] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163fa09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PU_DO\n",
       "237_236    22261\n",
       "236_237    18948\n",
       "236_236    14302\n",
       "264_264    14248\n",
       "237_237    13950\n",
       "           ...  \n",
       "141_72         1\n",
       "158_70         1\n",
       "50_64          1\n",
       "162_63         1\n",
       "262_53         1\n",
       "Name: count, Length: 21801, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PU_DO\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa8fdd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = (\n",
    "    df.groupby(\"PU_DO\")\n",
    "    .agg(duration=(\"duration\", \"mean\"), count=(\"duration\", \"count\"))\n",
    ").sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff0c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {k: v[\"duration\"] for k, v in df_lookup.iloc[:515].to_dict(orient=\"index\").items()}\n",
    "others_mean = df_lookup.iloc[515:][\"duration\"].mean()\n",
    "global_mean = df[\"duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a0360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_predict(pu_do: str) -> float:\n",
    "    return lookup_dict.get(pu_do, global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "685ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [lookup_predict(pu_do) for pu_do in df[\"PU_DO\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc292034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.410560890136322"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(df[\"duration\"].values, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3331d15",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b7c94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ac3ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb[\"PULocationID\"] = df_feb[\"PULocationID\"].astype(str)\n",
    "df_feb[\"DOLocationID\"] = df_feb[\"DOLocationID\"].astype(str)\n",
    "df_feb[\"PU_DO\"] = df_feb[\"PULocationID\"] + \"_\" + df_feb[\"DOLocationID\"]\n",
    "\n",
    "df_feb[\"duration\"] = (df_feb[\"tpep_dropoff_datetime\"] - df_feb[\"tpep_pickup_datetime\"]) / pd.Timedelta(minutes=1)\n",
    "df_feb = df_feb[(1 <= df_feb[\"duration\"]) & (df_feb[\"duration\"] <= 60)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49817cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.588254285274784"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [lookup_predict(pu_do) for pu_do in df_feb[\"PU_DO\"].values]\n",
    "root_mean_squared_error(df_feb[\"duration\"].values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b02bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
